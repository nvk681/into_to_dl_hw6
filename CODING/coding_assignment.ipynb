{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# print(torch._version_)\n",
        "# print(torchtext._version_)"
      ],
      "metadata": {
        "id": "3C2QUoAq_2_T",
        "outputId": "53ba9d7d-ecfc-4543-a64b-30c49aa195c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f75d6e37338a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(torch._version_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_version_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchtext' has no attribute '_version_'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U torch==1.8.0 torchtext==0.9.0"
      ],
      "metadata": {
        "id": "xPya0zLZ8KM0",
        "outputId": "767f2518-4df0-4d31-ccd2-89bbe976a858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 11 kB/s \n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 31.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.64.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0\n",
            "    Uninstalling torch-1.11.0:\n",
            "      Successfully uninstalled torch-1.11.0\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0 torchtext-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install torchtext"
      ],
      "metadata": {
        "id": "Lb7Tu0xT8BdW",
        "outputId": "08390b4e-f13b-460e-fa0b-6bc3f7171ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.21.6)\n",
            "Collecting torch==1.11.0\n",
            "  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 750.6 MB 11 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchtext) (4.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.0.0\n",
            "    Uninstalling torch-1.0.0:\n",
            "      Successfully uninstalled torch-1.0.0\n",
            "Successfully installed torch-1.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:51.161763Z",
          "iopub.status.busy": "2022-01-22T15:55:51.161511Z",
          "iopub.status.idle": "2022-01-22T15:55:51.165623Z",
          "shell.execute_reply": "2022-01-22T15:55:51.164626Z",
          "shell.execute_reply.started": "2022-01-22T15:55:51.161734Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKRmNXaQq0cy",
        "outputId": "96370eda-b2c3-4f68-9646-bd0163833a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8.0\n",
            "0.9.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchtext.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlKio-s1q0cz"
      },
      "source": [
        "# Import Required Libraries & Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:51.178773Z",
          "iopub.status.busy": "2022-01-22T15:55:51.178323Z",
          "iopub.status.idle": "2022-01-22T15:55:52.913605Z",
          "shell.execute_reply": "2022-01-22T15:55:52.912893Z",
          "shell.execute_reply.started": "2022-01-22T15:55:51.178736Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "qt7A9UiSq0c0",
        "outputId": "d19225fb-eb6c-44b9-aae9-757e9f9b0717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "5  Probably my all-time favorite movie, a story o...  positive\n",
              "6  I sure would like to see a resurrection of a u...  positive\n",
              "7  This show was an amazing, fresh & innovative i...  negative\n",
              "8  Encouraged by the positive comments about this...  negative\n",
              "9  If you like original gut wrenching laughter yo...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-506081ef-e60c-4e2f-8336-4f4953302cfc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Probably my all-time favorite movie, a story o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I sure would like to see a resurrection of a u...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Encouraged by the positive comments about this...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>If you like original gut wrenching laughter yo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-506081ef-e60c-4e2f-8336-4f4953302cfc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-506081ef-e60c-4e2f-8336-4f4953302cfc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-506081ef-e60c-4e2f-8336-4f4953302cfc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#importing the training data\n",
        "df=pd.read_csv('IMDB Dataset.csv')\n",
        "print(df.shape)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThWu0mLuq0c0"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:52.915240Z",
          "iopub.status.busy": "2022-01-22T15:55:52.914817Z",
          "iopub.status.idle": "2022-01-22T15:55:52.931074Z",
          "shell.execute_reply": "2022-01-22T15:55:52.930198Z",
          "shell.execute_reply.started": "2022-01-22T15:55:52.915202Z"
        },
        "trusted": true,
        "id": "IsVEVc7Lq0c1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "sentiment : 0 = negative, 1 = positive \n",
        "use the following to get the sentiment of a sentence :  \n",
        "sentiment = 0 if sentiment is negative else 1\n",
        "\n",
        "\n",
        "use np.where to get the sentiment of a sentence :\n",
        "\"\"\"\n",
        "df['sentiment'] = np.where(df['sentiment'] == 'positive', 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:52.933556Z",
          "iopub.status.busy": "2022-01-22T15:55:52.933295Z",
          "iopub.status.idle": "2022-01-22T15:55:52.942961Z",
          "shell.execute_reply": "2022-01-22T15:55:52.942162Z",
          "shell.execute_reply.started": "2022-01-22T15:55:52.933524Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "CZJ4HwVIq0c1",
        "outputId": "9932bed0-bae8-4fac-b5d4-d15240779b0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-108ace07-104e-4503-9ced-a9fed0d51476\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-108ace07-104e-4503-9ced-a9fed0d51476')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-108ace07-104e-4503-9ced-a9fed0d51476 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-108ace07-104e-4503-9ced-a9fed0d51476');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:52.944777Z",
          "iopub.status.busy": "2022-01-22T15:55:52.944484Z",
          "iopub.status.idle": "2022-01-22T15:55:52.951178Z",
          "shell.execute_reply": "2022-01-22T15:55:52.950461Z",
          "shell.execute_reply.started": "2022-01-22T15:55:52.944743Z"
        },
        "trusted": true,
        "id": "-RHPAGZKq0c1"
      },
      "outputs": [],
      "source": [
        "df.columns = ['TEXT_COLUMN_NAME', 'LABEL_COLUMN_NAME']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:52.953080Z",
          "iopub.status.busy": "2022-01-22T15:55:52.952741Z",
          "iopub.status.idle": "2022-01-22T15:55:53.553818Z",
          "shell.execute_reply": "2022-01-22T15:55:53.553120Z",
          "shell.execute_reply.started": "2022-01-22T15:55:52.952969Z"
        },
        "trusted": true,
        "id": "bnav0wubq0c1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Load the spacy model and load the English language model from https://spacy.io/usage/models\n",
        "\"\"\"\n",
        "# python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# spacy.### ADD YOUR SPACY MODEL HERE ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:53.629426Z",
          "iopub.status.busy": "2022-01-22T15:55:53.629143Z",
          "iopub.status.idle": "2022-01-22T15:55:53.637675Z",
          "shell.execute_reply": "2022-01-22T15:55:53.636930Z",
          "shell.execute_reply.started": "2022-01-22T15:55:53.629373Z"
        },
        "trusted": true,
        "id": "xim4O3iRq0c1"
      },
      "outputs": [],
      "source": [
        "# general Settings\n",
        "\n",
        "RANDOM_SEED = 123\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "VOCABULARY_SIZE = 20000\n",
        "LEARNING_RATE = 0.005 ### ADD YOUR LEARNING RATE HERE ###\n",
        "BATCH_SIZE = 126### ADD YOUR BATCH SIZE HERE ###\n",
        "NUM_EPOCHS = 10 ### ADD YOUR NUMBER OF EPOCHS HERE ###\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "EMBEDDING_DIM = 400### ADD YOUR EMBEDDING DIMENSION HERE ###\n",
        "HIDDEN_DIM = 128 ### ADD YOUR HIDDEN DIMENSION HERE ###\n",
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-WcdMhvxzcC",
        "outputId": "ffa6cbda-a7a7-41f9-d4e2-089ad83776bb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.11.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchtext) (4.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "934XMm9Lq0c2"
      },
      "source": [
        "*italicized text*# Text & label Preparation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install torch==1.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "ooQ8tnyV6355",
        "outputId": "8f980f6e-e5ea-4eff-9e49-5838fb139b14"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.0.0\n",
            "  Downloading torch-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (591.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 591.8 MB 508 bytes/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.0.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.0.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.0.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:53.639530Z",
          "iopub.status.busy": "2022-01-22T15:55:53.639045Z",
          "iopub.status.idle": "2022-01-22T15:55:54.191068Z",
          "shell.execute_reply": "2022-01-22T15:55:54.190361Z",
          "shell.execute_reply.started": "2022-01-22T15:55:53.639494Z"
        },
        "trusted": true,
        "id": "ObU7NKFxq0c2"
      },
      "outputs": [],
      "source": [
        "# Define feature processing\n",
        "\"\"\"\n",
        "Define the fields for the data.\n",
        "\"\"\"\n",
        "# from torchtext import data\n",
        "# TEXT = torchtext.data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')\n",
        "TEXT = torchtext.legacy.data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:54.194504Z",
          "iopub.status.busy": "2022-01-22T15:55:54.194231Z",
          "iopub.status.idle": "2022-01-22T15:55:54.198370Z",
          "shell.execute_reply": "2022-01-22T15:55:54.197471Z",
          "shell.execute_reply.started": "2022-01-22T15:55:54.194470Z"
        },
        "trusted": true,
        "id": "GvJk1roTq0c2"
      },
      "outputs": [],
      "source": [
        "# Define Label processing\n",
        "LABEL = torchtext.legacy.data.LabelField(dtype = torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:54.200276Z",
          "iopub.status.busy": "2022-01-22T15:55:54.199959Z",
          "iopub.status.idle": "2022-01-22T15:55:57.099915Z",
          "shell.execute_reply": "2022-01-22T15:55:57.099168Z",
          "shell.execute_reply.started": "2022-01-22T15:55:54.200243Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BbURsOlCq0c2",
        "outputId": "594f0ea8-f1ba-4427-e9e5-1f48f0dbd45b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    TEXT_COLUMN_NAME  LABEL_COLUMN_NAME\n",
              "0  One of the other reviewers has mentioned that ...                  1\n",
              "1  A wonderful little production. <br /><br />The...                  1\n",
              "2  I thought this was a wonderful way to spend ti...                  1\n",
              "3  Basically there's a family where a little boy ...                  0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...                  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69b5cb28-4a9e-4b6e-bf8e-17d0e4b441fc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXT_COLUMN_NAME</th>\n",
              "      <th>LABEL_COLUMN_NAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69b5cb28-4a9e-4b6e-bf8e-17d0e4b441fc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69b5cb28-4a9e-4b6e-bf8e-17d0e4b441fc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69b5cb28-4a9e-4b6e-bf8e-17d0e4b441fc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\"\"\"\n",
        "Define the fields for the data.\n",
        "\"\"\"\n",
        "\n",
        "df.to_csv('moviedata.csv', index = None)\n",
        "df = pd.read_csv('moviedata.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:55:57.102513Z",
          "iopub.status.busy": "2022-01-22T15:55:57.102056Z",
          "iopub.status.idle": "2022-01-22T15:56:41.889075Z",
          "shell.execute_reply": "2022-01-22T15:56:41.888358Z",
          "shell.execute_reply.started": "2022-01-22T15:55:57.102470Z"
        },
        "trusted": true,
        "id": "VWynC44bq0c3"
      },
      "outputs": [],
      "source": [
        "# process the dataset\n",
        "# TEXT = LABEL = []\n",
        "fields = [('TEXT_COLUMN_NAME', TEXT), ('LABEL_COLUMN_NAME', LABEL)]\n",
        "\n",
        "dataset = torchtext.legacy.data.TabularDataset(\n",
        "                    path = '/content/moviedata.csv', ### ADD YOUR DATASET PATH HERE ###\n",
        "                    format = 'csv', ### ADD YOUR DATASET FORMAT HERE ###\n",
        "                    skip_header = True, ### ADD YOUR SKIP HEADER HERE ### \n",
        "                    fields =  fields#(\"TEXT_COLUMN_NAME\",\t\"LABEL_COLUMN_NAME\")### ADD YOUR FIELDS HERE ### \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_k28tJBq0c3"
      },
      "source": [
        "# Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:41.890714Z",
          "iopub.status.busy": "2022-01-22T15:56:41.890459Z",
          "iopub.status.idle": "2022-01-22T15:56:41.961168Z",
          "shell.execute_reply": "2022-01-22T15:56:41.960371Z",
          "shell.execute_reply.started": "2022-01-22T15:56:41.890680Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fceN707cq0c3",
        "outputId": "32a26ec0-7c31-4c10-fcad-6e377578c94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data 40000\n",
            "Length of test data 10000\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into train and test set\n",
        "\n",
        "train_data, test_data = dataset.split(split_ratio = [0.8, 0.2], random_state = random.seed(RANDOM_SEED))\n",
        "\n",
        "print('Length of train data', len(train_data))\n",
        "print('Length of test data', len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:41.962867Z",
          "iopub.status.busy": "2022-01-22T15:56:41.962611Z",
          "iopub.status.idle": "2022-01-22T15:56:42.018970Z",
          "shell.execute_reply": "2022-01-22T15:56:42.017378Z",
          "shell.execute_reply.started": "2022-01-22T15:56:41.962832Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxrUKgiGq0c3",
        "outputId": "988876f3-3d93-489a-d259-aa57861e8f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train data 34000\n",
            "Length of valid data 6000\n"
          ]
        }
      ],
      "source": [
        "train_data, val_data = train_data.split(split_ratio = [0.85, 0.15], random_state = random.seed(RANDOM_SEED))\n",
        "\n",
        "print('Length of train data', len(train_data))\n",
        "print('Length of valid data', len(val_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OrydghHq0c4"
      },
      "source": [
        "# Data Observation after Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:42.020384Z",
          "iopub.status.busy": "2022-01-22T15:56:42.020132Z",
          "iopub.status.idle": "2022-01-22T15:56:42.026208Z",
          "shell.execute_reply": "2022-01-22T15:56:42.025377Z",
          "shell.execute_reply.started": "2022-01-22T15:56:42.020349Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39O7Io9lq0c4",
        "outputId": "9d88d4ae-c6a0-4a2c-f850-1f216e8f49fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'TEXT_COLUMN_NAME': ['Flipping', 'through', 'the', 'channels', 'I', 'was', 'lucky', 'enough', 'to', 'stumble', 'upon', 'the', 'beginning', 'of', 'this', 'movie', '.', 'I', 'must', 'admit', 'that', 'it', 'grabbed', 'my', 'attention', 'almost', 'immediately', '.', 'I', 'love', 'older', 'films', 'and', 'this', 'is', 'or', 'should', 'be', 'considered', 'a', 'classic', '!', 'One', 'of', 'the', 'most', 'wonderful', 'rarities', 'of', 'this', 'movie', 'is', 'that', 'the', 'main', 'character', 'was', 'not', 'only', 'female', 'but', 'she', 'was', 'also', 'a', 'bad', 'girl', '.', 'I', 'highly', 'recommend', 'this', 'movie', '!'], 'LABEL_COLUMN_NAME': '1'}\n"
          ]
        }
      ],
      "source": [
        "# Look at first traning example\n",
        "\n",
        "print(vars(train_data.examples[2000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:42.028212Z",
          "iopub.status.busy": "2022-01-22T15:56:42.027904Z",
          "iopub.status.idle": "2022-01-22T15:56:43.688300Z",
          "shell.execute_reply": "2022-01-22T15:56:43.687534Z",
          "shell.execute_reply.started": "2022-01-22T15:56:42.028178Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrl0ez-Wq0c4",
        "outputId": "3e7134a5-543e-4200-d835-ae4a2f4453f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary size: 20002\n",
            "Label Size: 2\n"
          ]
        }
      ],
      "source": [
        "# Build Vocabulary\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = VOCABULARY_SIZE)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print(f'vocabulary size: {len(TEXT.vocab)}')\n",
        "print(f'Label Size: {len(LABEL.vocab)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wts_9j4uq0c5"
      },
      "source": [
        " 2 extra value in vocabulary is because added (unknown) and (padding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.690179Z",
          "iopub.status.busy": "2022-01-22T15:56:43.689727Z",
          "iopub.status.idle": "2022-01-22T15:56:43.726493Z",
          "shell.execute_reply": "2022-01-22T15:56:43.725793Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.690127Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q37twWQfq0c5",
        "outputId": "aef43b8f-6e6a-4bf5-e9be-7dd39c6d65bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 390972), (',', 369444), ('.', 318719), ('a', 210502), ('and', 210006), ('of', 194658), ('to', 180163), ('is', 145895), ('in', 118266), ('I', 105681)]\n"
          ]
        }
      ],
      "source": [
        "# Print the most common words: Use the most_common method of the TEXT vocabulary\n",
        "# import collections\n",
        "\n",
        "most_common_words = TEXT.vocab.freqs.most_common(10)\n",
        "print(most_common_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.727759Z",
          "iopub.status.busy": "2022-01-22T15:56:43.727533Z",
          "iopub.status.idle": "2022-01-22T15:56:43.733148Z",
          "shell.execute_reply": "2022-01-22T15:56:43.732231Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.727727Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMUCbCpHq0c5",
        "outputId": "43cd9801-d47b-417e-b9e4-2cb189e77dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is', 'in', 'I', 'it', 'that', '\"', \"'s\", 'this', '-', '/><br', 'was']\n"
          ]
        }
      ],
      "source": [
        "# Token corresponding to first 10 Indices\n",
        "\n",
        "print(TEXT.vocab.itos[:20]) #itos = Integer to string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKDDDA5Zq0c5"
      },
      "source": [
        "# Data Preparation for Batch wise Implimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.760843Z",
          "iopub.status.busy": "2022-01-22T15:56:43.760082Z",
          "iopub.status.idle": "2022-01-22T15:56:43.766731Z",
          "shell.execute_reply": "2022-01-22T15:56:43.766017Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.760804Z"
        },
        "trusted": true,
        "id": "1jNvtBT_q0c6"
      },
      "outputs": [],
      "source": [
        "# Define Dataloader\n",
        "    # sort = False, #don't sort test/validation data\n",
        "    # batch_size=BATCH_SIZE,\n",
        "    # device=device)\n",
        "train_loader, valid_loader, test_loader = torchtext.legacy.data.BucketIterator.splits(\n",
        "        (train_data, val_data, test_data), ### ADD YOUR SPLIT DATA HERE (Make sure you add it in a tuple) ###\n",
        "        batch_size = 64, ### ADD YOUR BATCH SIZE HERE ###\n",
        "        sort_within_batch = False, ### ADD YOUR SORT WITHIN BATCH HERE ### \n",
        "        sort_key = lambda x : len(x.TEXT_COLUMN_NAME), \n",
        "        #device = DEVICE\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.768827Z",
          "iopub.status.busy": "2022-01-22T15:56:43.768197Z",
          "iopub.status.idle": "2022-01-22T15:56:43.900963Z",
          "shell.execute_reply": "2022-01-22T15:56:43.900283Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.768790Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jllOrNvqq0c6",
        "outputId": "ff464aab-e959-4daa-c3d3-f9dc8ddb9318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "Text matrix size: torch.Size([1039, 64])\n",
            "Target vector size: torch.Size([64])\n",
            "\n",
            "Valid:\n",
            "Text matrix size: torch.Size([50, 64])\n",
            "Target vector size: torch.Size([64])\n",
            "\n",
            "Test:\n",
            "Text matrix size: torch.Size([44, 64])\n",
            "Target vector size: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# Testing the iterators (note that the number of rows depends on the longest document in the respective batch):\n",
        "\n",
        "print('Train')\n",
        "for batch in train_loader:\n",
        "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
        "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nValid:')\n",
        "for batch in valid_loader:\n",
        "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
        "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nTest:')\n",
        "for batch in test_loader:\n",
        "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
        "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.902778Z",
          "iopub.status.busy": "2022-01-22T15:56:43.902325Z",
          "iopub.status.idle": "2022-01-22T15:56:43.909421Z",
          "shell.execute_reply": "2022-01-22T15:56:43.908776Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.902740Z"
        },
        "trusted": true,
        "id": "EBSpo94Aq0c6"
      },
      "outputs": [],
      "source": [
        "# train_loader, valid_loader, test_loader = torchtext.legacy.data.BucketIterator.splits(\n",
        "#         , ### ADD YOUR SPLIT DATA HERE (Make sure you add it in a tuple) ###\n",
        "#         batch_size = 64, ### ADD YOUR BATCH SIZE HERE ###\n",
        "#         sort_within_batch = Flase, ### ADD YOUR SORT WITHIN BATCH HERE ###\n",
        "#         sort_key = lambda x : len(x.TEXT_COLUMN_NAME),\n",
        "#         device = DEVICE\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9lwbkxKq0c7"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.910544Z",
          "iopub.status.busy": "2022-01-22T15:56:43.910274Z",
          "iopub.status.idle": "2022-01-22T15:56:43.920687Z",
          "shell.execute_reply": "2022-01-22T15:56:43.919977Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.910510Z"
        },
        "trusted": true,
        "id": "xpT703etq0c7"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        ### ADD YOUR CODE HERE ###\n",
        "        \n",
        "        \n",
        "        ### END YOUR CODE ### \n",
        "\n",
        "    def forward(self, text):\n",
        "        ### ADD YOUR CODE HERE ###\n",
        "        # text dim: [sentence length, batch size]\n",
        "        \n",
        "        # embedded dim: [sentence length, batch size, embedding dim]\n",
        "        \n",
        "        # output dim: [sentence length, batch size, hidden dim]\n",
        "        # hidden dim: [1, batch size, hidden dim]\n",
        "\n",
        "        # hidden dim: [batch size, hidden dim]\n",
        "\n",
        "        \n",
        "        ### END YOUR CODE ###\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:43.922337Z",
          "iopub.status.busy": "2022-01-22T15:56:43.921742Z",
          "iopub.status.idle": "2022-01-22T15:56:51.579010Z",
          "shell.execute_reply": "2022-01-22T15:56:51.578073Z",
          "shell.execute_reply.started": "2022-01-22T15:56:43.922287Z"
        },
        "trusted": true,
        "id": "5ZLRzRQPq0c7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "model = RNN(input_dim=, ### ADD YOUR INPUT DIM HERE. This can be the length of your vocabulary or the embedding dim ###\n",
        "            embedding_dim=, ### ADD YOUR EMBEDDING DIM HERE ###\n",
        "            hidden_dim=, ### ADD YOUR HIDDEN DIM HERE ###\n",
        "            output_dim=  ### ADD NUMBER OF CLASSES HERE ###\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "optimizer = ### ADD YOUR OPTIMIZER HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goC2gMg2q0c7"
      },
      "source": [
        "# Define Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:51.581205Z",
          "iopub.status.busy": "2022-01-22T15:56:51.580712Z",
          "iopub.status.idle": "2022-01-22T15:56:51.589897Z",
          "shell.execute_reply": "2022-01-22T15:56:51.588931Z",
          "shell.execute_reply.started": "2022-01-22T15:56:51.581131Z"
        },
        "trusted": true,
        "id": "sOj5Lt3Hq0c7"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "            features = features.to(device)\n",
        "            targets = targets.float().to(device)\n",
        "\n",
        "            logits = model(features)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzTv-8QAq0c8"
      },
      "source": [
        "# Model Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T15:56:51.596066Z",
          "iopub.status.busy": "2022-01-22T15:56:51.595269Z",
          "iopub.status.idle": "2022-01-22T16:41:22.979843Z",
          "shell.execute_reply": "2022-01-22T16:41:22.979001Z",
          "shell.execute_reply.started": "2022-01-22T15:56:51.596024Z"
        },
        "trusted": true,
        "id": "wEFwnvJUq0c8",
        "outputId": "9c512cb3-ed6e-4437-e6cf-a793a28c7895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001/050 | Batch 000/266 | Loss: 0.7136\n",
            "Epoch: 001/050 | Batch 050/266 | Loss: 0.6993\n",
            "Epoch: 001/050 | Batch 100/266 | Loss: 0.6898\n",
            "Epoch: 001/050 | Batch 150/266 | Loss: 0.6925\n",
            "Epoch: 001/050 | Batch 200/266 | Loss: 0.6960\n",
            "Epoch: 001/050 | Batch 250/266 | Loss: 0.6951\n",
            "training accuracy: 49.94%\n",
            "valid accuracy: 49.83%\n",
            "Time elapsed: 0.91 min\n",
            "Epoch: 002/050 | Batch 000/266 | Loss: 0.6984\n",
            "Epoch: 002/050 | Batch 050/266 | Loss: 0.6915\n",
            "Epoch: 002/050 | Batch 100/266 | Loss: 0.6940\n",
            "Epoch: 002/050 | Batch 150/266 | Loss: 0.6953\n",
            "Epoch: 002/050 | Batch 200/266 | Loss: 0.6935\n",
            "Epoch: 002/050 | Batch 250/266 | Loss: 0.6922\n",
            "training accuracy: 50.00%\n",
            "valid accuracy: 50.07%\n",
            "Time elapsed: 1.80 min\n",
            "Epoch: 003/050 | Batch 000/266 | Loss: 0.6908\n",
            "Epoch: 003/050 | Batch 050/266 | Loss: 0.6975\n",
            "Epoch: 003/050 | Batch 100/266 | Loss: 0.7004\n",
            "Epoch: 003/050 | Batch 150/266 | Loss: 0.6952\n",
            "Epoch: 003/050 | Batch 200/266 | Loss: 0.6906\n",
            "Epoch: 003/050 | Batch 250/266 | Loss: 0.6913\n",
            "training accuracy: 50.34%\n",
            "valid accuracy: 50.15%\n",
            "Time elapsed: 2.68 min\n",
            "Epoch: 004/050 | Batch 000/266 | Loss: 0.6922\n",
            "Epoch: 004/050 | Batch 050/266 | Loss: 0.6990\n",
            "Epoch: 004/050 | Batch 100/266 | Loss: 0.6922\n",
            "Epoch: 004/050 | Batch 150/266 | Loss: 0.6963\n",
            "Epoch: 004/050 | Batch 200/266 | Loss: 0.6948\n",
            "Epoch: 004/050 | Batch 250/266 | Loss: 0.6914\n",
            "training accuracy: 50.35%\n",
            "valid accuracy: 50.00%\n",
            "Time elapsed: 3.57 min\n",
            "Epoch: 005/050 | Batch 000/266 | Loss: 0.6903\n",
            "Epoch: 005/050 | Batch 050/266 | Loss: 0.6928\n",
            "Epoch: 005/050 | Batch 100/266 | Loss: 0.6912\n",
            "Epoch: 005/050 | Batch 150/266 | Loss: 0.6949\n",
            "Epoch: 005/050 | Batch 200/266 | Loss: 0.7001\n",
            "Epoch: 005/050 | Batch 250/266 | Loss: 0.6893\n",
            "training accuracy: 50.37%\n",
            "valid accuracy: 50.30%\n",
            "Time elapsed: 4.47 min\n",
            "Epoch: 006/050 | Batch 000/266 | Loss: 0.6971\n",
            "Epoch: 006/050 | Batch 050/266 | Loss: 0.6890\n",
            "Epoch: 006/050 | Batch 100/266 | Loss: 0.6867\n",
            "Epoch: 006/050 | Batch 150/266 | Loss: 0.7023\n",
            "Epoch: 006/050 | Batch 200/266 | Loss: 0.6900\n",
            "Epoch: 006/050 | Batch 250/266 | Loss: 0.6885\n",
            "training accuracy: 50.19%\n",
            "valid accuracy: 50.47%\n",
            "Time elapsed: 5.35 min\n",
            "Epoch: 007/050 | Batch 000/266 | Loss: 0.6885\n",
            "Epoch: 007/050 | Batch 050/266 | Loss: 0.7028\n",
            "Epoch: 007/050 | Batch 100/266 | Loss: 0.6885\n",
            "Epoch: 007/050 | Batch 150/266 | Loss: 0.6889\n",
            "Epoch: 007/050 | Batch 200/266 | Loss: 0.6877\n",
            "Epoch: 007/050 | Batch 250/266 | Loss: 0.6882\n",
            "training accuracy: 50.41%\n",
            "valid accuracy: 50.20%\n",
            "Time elapsed: 6.24 min\n",
            "Epoch: 008/050 | Batch 000/266 | Loss: 0.6899\n",
            "Epoch: 008/050 | Batch 050/266 | Loss: 0.7012\n",
            "Epoch: 008/050 | Batch 100/266 | Loss: 0.6880\n",
            "Epoch: 008/050 | Batch 150/266 | Loss: 0.6928\n",
            "Epoch: 008/050 | Batch 200/266 | Loss: 0.6917\n",
            "Epoch: 008/050 | Batch 250/266 | Loss: 0.6895\n",
            "training accuracy: 61.00%\n",
            "valid accuracy: 60.33%\n",
            "Time elapsed: 7.13 min\n",
            "Epoch: 009/050 | Batch 000/266 | Loss: 0.6768\n",
            "Epoch: 009/050 | Batch 050/266 | Loss: 0.6781\n",
            "Epoch: 009/050 | Batch 100/266 | Loss: 0.6610\n",
            "Epoch: 009/050 | Batch 150/266 | Loss: 0.6498\n",
            "Epoch: 009/050 | Batch 200/266 | Loss: 0.6359\n",
            "Epoch: 009/050 | Batch 250/266 | Loss: 0.5808\n",
            "training accuracy: 72.84%\n",
            "valid accuracy: 67.05%\n",
            "Time elapsed: 8.03 min\n",
            "Epoch: 010/050 | Batch 000/266 | Loss: 0.5725\n",
            "Epoch: 010/050 | Batch 050/266 | Loss: 0.5274\n",
            "Epoch: 010/050 | Batch 100/266 | Loss: 0.4851\n",
            "Epoch: 010/050 | Batch 150/266 | Loss: 0.4642\n",
            "Epoch: 010/050 | Batch 200/266 | Loss: 0.5052\n",
            "Epoch: 010/050 | Batch 250/266 | Loss: 0.5080\n",
            "training accuracy: 80.24%\n",
            "valid accuracy: 75.40%\n",
            "Time elapsed: 8.92 min\n",
            "Epoch: 011/050 | Batch 000/266 | Loss: 0.4163\n",
            "Epoch: 011/050 | Batch 050/266 | Loss: 0.3634\n",
            "Epoch: 011/050 | Batch 100/266 | Loss: 0.4942\n",
            "Epoch: 011/050 | Batch 150/266 | Loss: 0.3994\n",
            "Epoch: 011/050 | Batch 200/266 | Loss: 0.3422\n",
            "Epoch: 011/050 | Batch 250/266 | Loss: 0.3313\n",
            "training accuracy: 83.18%\n",
            "valid accuracy: 76.53%\n",
            "Time elapsed: 9.81 min\n",
            "Epoch: 012/050 | Batch 000/266 | Loss: 0.3633\n",
            "Epoch: 012/050 | Batch 050/266 | Loss: 0.3800\n",
            "Epoch: 012/050 | Batch 100/266 | Loss: 0.4197\n",
            "Epoch: 012/050 | Batch 150/266 | Loss: 0.3929\n",
            "Epoch: 012/050 | Batch 200/266 | Loss: 0.3593\n",
            "Epoch: 012/050 | Batch 250/266 | Loss: 0.5156\n",
            "training accuracy: 69.09%\n",
            "valid accuracy: 70.75%\n",
            "Time elapsed: 10.70 min\n",
            "Epoch: 013/050 | Batch 000/266 | Loss: 0.5412\n",
            "Epoch: 013/050 | Batch 050/266 | Loss: 0.3211\n",
            "Epoch: 013/050 | Batch 100/266 | Loss: 0.4427\n",
            "Epoch: 013/050 | Batch 150/266 | Loss: 0.4895\n",
            "Epoch: 013/050 | Batch 200/266 | Loss: 0.4497\n",
            "Epoch: 013/050 | Batch 250/266 | Loss: 0.4857\n",
            "training accuracy: 79.30%\n",
            "valid accuracy: 74.05%\n",
            "Time elapsed: 11.59 min\n",
            "Epoch: 014/050 | Batch 000/266 | Loss: 0.4381\n",
            "Epoch: 014/050 | Batch 050/266 | Loss: 0.4736\n",
            "Epoch: 014/050 | Batch 100/266 | Loss: 0.4543\n",
            "Epoch: 014/050 | Batch 150/266 | Loss: 0.5307\n",
            "Epoch: 014/050 | Batch 200/266 | Loss: 0.4419\n",
            "Epoch: 014/050 | Batch 250/266 | Loss: 0.4583\n",
            "training accuracy: 83.13%\n",
            "valid accuracy: 76.15%\n",
            "Time elapsed: 12.48 min\n",
            "Epoch: 015/050 | Batch 000/266 | Loss: 0.3551\n",
            "Epoch: 015/050 | Batch 050/266 | Loss: 0.3994\n",
            "Epoch: 015/050 | Batch 100/266 | Loss: 0.3667\n",
            "Epoch: 015/050 | Batch 150/266 | Loss: 0.3518\n",
            "Epoch: 015/050 | Batch 200/266 | Loss: 0.5011\n",
            "Epoch: 015/050 | Batch 250/266 | Loss: 0.4299\n",
            "training accuracy: 83.60%\n",
            "valid accuracy: 77.62%\n",
            "Time elapsed: 13.37 min\n",
            "Epoch: 016/050 | Batch 000/266 | Loss: 0.4020\n",
            "Epoch: 016/050 | Batch 050/266 | Loss: 0.2846\n",
            "Epoch: 016/050 | Batch 100/266 | Loss: 0.3781\n",
            "Epoch: 016/050 | Batch 150/266 | Loss: 0.3510\n",
            "Epoch: 016/050 | Batch 200/266 | Loss: 0.4692\n",
            "Epoch: 016/050 | Batch 250/266 | Loss: 0.4962\n",
            "training accuracy: 82.42%\n",
            "valid accuracy: 76.37%\n",
            "Time elapsed: 14.26 min\n",
            "Epoch: 017/050 | Batch 000/266 | Loss: 0.3440\n",
            "Epoch: 017/050 | Batch 050/266 | Loss: 0.3849\n",
            "Epoch: 017/050 | Batch 100/266 | Loss: 0.3189\n",
            "Epoch: 017/050 | Batch 150/266 | Loss: 0.3611\n",
            "Epoch: 017/050 | Batch 200/266 | Loss: 0.5052\n",
            "Epoch: 017/050 | Batch 250/266 | Loss: 0.3443\n",
            "training accuracy: 86.80%\n",
            "valid accuracy: 78.98%\n",
            "Time elapsed: 15.15 min\n",
            "Epoch: 018/050 | Batch 000/266 | Loss: 0.3912\n",
            "Epoch: 018/050 | Batch 050/266 | Loss: 0.3250\n",
            "Epoch: 018/050 | Batch 100/266 | Loss: 0.2453\n",
            "Epoch: 018/050 | Batch 150/266 | Loss: 0.3806\n",
            "Epoch: 018/050 | Batch 200/266 | Loss: 0.3616\n",
            "Epoch: 018/050 | Batch 250/266 | Loss: 0.3265\n",
            "training accuracy: 87.61%\n",
            "valid accuracy: 79.92%\n",
            "Time elapsed: 16.04 min\n",
            "Epoch: 019/050 | Batch 000/266 | Loss: 0.3043\n",
            "Epoch: 019/050 | Batch 050/266 | Loss: 0.3221\n",
            "Epoch: 019/050 | Batch 100/266 | Loss: 0.4061\n",
            "Epoch: 019/050 | Batch 150/266 | Loss: 0.2301\n",
            "Epoch: 019/050 | Batch 200/266 | Loss: 0.3515\n",
            "Epoch: 019/050 | Batch 250/266 | Loss: 0.2703\n",
            "training accuracy: 89.39%\n",
            "valid accuracy: 80.37%\n",
            "Time elapsed: 16.93 min\n",
            "Epoch: 020/050 | Batch 000/266 | Loss: 0.2528\n",
            "Epoch: 020/050 | Batch 050/266 | Loss: 0.2528\n",
            "Epoch: 020/050 | Batch 100/266 | Loss: 0.2247\n",
            "Epoch: 020/050 | Batch 150/266 | Loss: 0.3969\n",
            "Epoch: 020/050 | Batch 200/266 | Loss: 0.2890\n",
            "Epoch: 020/050 | Batch 250/266 | Loss: 0.3351\n",
            "training accuracy: 90.59%\n",
            "valid accuracy: 80.63%\n",
            "Time elapsed: 17.81 min\n",
            "Epoch: 021/050 | Batch 000/266 | Loss: 0.2280\n",
            "Epoch: 021/050 | Batch 050/266 | Loss: 0.3016\n",
            "Epoch: 021/050 | Batch 100/266 | Loss: 0.2382\n",
            "Epoch: 021/050 | Batch 150/266 | Loss: 0.1862\n",
            "Epoch: 021/050 | Batch 200/266 | Loss: 0.2989\n",
            "Epoch: 021/050 | Batch 250/266 | Loss: 0.2516\n",
            "training accuracy: 84.72%\n",
            "valid accuracy: 76.12%\n",
            "Time elapsed: 18.71 min\n",
            "Epoch: 022/050 | Batch 000/266 | Loss: 0.3242\n",
            "Epoch: 022/050 | Batch 050/266 | Loss: 0.3015\n",
            "Epoch: 022/050 | Batch 100/266 | Loss: 0.2937\n",
            "Epoch: 022/050 | Batch 150/266 | Loss: 0.3523\n",
            "Epoch: 022/050 | Batch 200/266 | Loss: 0.3036\n",
            "Epoch: 022/050 | Batch 250/266 | Loss: 0.3675\n",
            "training accuracy: 90.17%\n",
            "valid accuracy: 80.48%\n",
            "Time elapsed: 19.59 min\n",
            "Epoch: 023/050 | Batch 000/266 | Loss: 0.2873\n",
            "Epoch: 023/050 | Batch 050/266 | Loss: 0.1397\n",
            "Epoch: 023/050 | Batch 100/266 | Loss: 0.3403\n",
            "Epoch: 023/050 | Batch 150/266 | Loss: 0.2765\n",
            "Epoch: 023/050 | Batch 200/266 | Loss: 0.2996\n",
            "Epoch: 023/050 | Batch 250/266 | Loss: 0.3217\n",
            "training accuracy: 91.32%\n",
            "valid accuracy: 81.17%\n",
            "Time elapsed: 20.48 min\n",
            "Epoch: 024/050 | Batch 000/266 | Loss: 0.2541\n",
            "Epoch: 024/050 | Batch 050/266 | Loss: 0.2653\n",
            "Epoch: 024/050 | Batch 100/266 | Loss: 0.3196\n",
            "Epoch: 024/050 | Batch 150/266 | Loss: 0.2968\n",
            "Epoch: 024/050 | Batch 200/266 | Loss: 0.2556\n",
            "Epoch: 024/050 | Batch 250/266 | Loss: 0.2107\n",
            "training accuracy: 91.43%\n",
            "valid accuracy: 81.05%\n",
            "Time elapsed: 21.37 min\n",
            "Epoch: 025/050 | Batch 000/266 | Loss: 0.2195\n",
            "Epoch: 025/050 | Batch 050/266 | Loss: 0.1656\n",
            "Epoch: 025/050 | Batch 100/266 | Loss: 0.1731\n",
            "Epoch: 025/050 | Batch 150/266 | Loss: 0.2153\n",
            "Epoch: 025/050 | Batch 200/266 | Loss: 0.2055\n",
            "Epoch: 025/050 | Batch 250/266 | Loss: 0.2600\n",
            "training accuracy: 92.23%\n",
            "valid accuracy: 81.10%\n",
            "Time elapsed: 22.25 min\n",
            "Epoch: 026/050 | Batch 000/266 | Loss: 0.1238\n",
            "Epoch: 026/050 | Batch 050/266 | Loss: 0.1927\n",
            "Epoch: 026/050 | Batch 100/266 | Loss: 0.2172\n",
            "Epoch: 026/050 | Batch 150/266 | Loss: 0.2625\n",
            "Epoch: 026/050 | Batch 200/266 | Loss: 0.2208\n",
            "Epoch: 026/050 | Batch 250/266 | Loss: 0.1727\n",
            "training accuracy: 92.68%\n",
            "valid accuracy: 81.42%\n",
            "Time elapsed: 23.14 min\n",
            "Epoch: 027/050 | Batch 000/266 | Loss: 0.2543\n",
            "Epoch: 027/050 | Batch 050/266 | Loss: 0.1353\n",
            "Epoch: 027/050 | Batch 100/266 | Loss: 0.2206\n",
            "Epoch: 027/050 | Batch 150/266 | Loss: 0.2279\n",
            "Epoch: 027/050 | Batch 200/266 | Loss: 0.2454\n",
            "Epoch: 027/050 | Batch 250/266 | Loss: 0.2585\n",
            "training accuracy: 92.58%\n",
            "valid accuracy: 81.02%\n",
            "Time elapsed: 24.03 min\n",
            "Epoch: 028/050 | Batch 000/266 | Loss: 0.3122\n",
            "Epoch: 028/050 | Batch 050/266 | Loss: 0.1922\n",
            "Epoch: 028/050 | Batch 100/266 | Loss: 0.1996\n",
            "Epoch: 028/050 | Batch 150/266 | Loss: 0.2465\n",
            "Epoch: 028/050 | Batch 200/266 | Loss: 0.2342\n",
            "Epoch: 028/050 | Batch 250/266 | Loss: 0.3055\n",
            "training accuracy: 93.01%\n",
            "valid accuracy: 80.57%\n",
            "Time elapsed: 24.92 min\n",
            "Epoch: 029/050 | Batch 000/266 | Loss: 0.1589\n",
            "Epoch: 029/050 | Batch 050/266 | Loss: 0.1290\n",
            "Epoch: 029/050 | Batch 100/266 | Loss: 0.1324\n",
            "Epoch: 029/050 | Batch 150/266 | Loss: 0.2556\n",
            "Epoch: 029/050 | Batch 200/266 | Loss: 0.2054\n",
            "Epoch: 029/050 | Batch 250/266 | Loss: 0.2755\n",
            "training accuracy: 93.64%\n",
            "valid accuracy: 81.25%\n",
            "Time elapsed: 25.81 min\n",
            "Epoch: 030/050 | Batch 000/266 | Loss: 0.1665\n",
            "Epoch: 030/050 | Batch 050/266 | Loss: 0.2120\n",
            "Epoch: 030/050 | Batch 100/266 | Loss: 0.2313\n",
            "Epoch: 030/050 | Batch 150/266 | Loss: 0.2251\n",
            "Epoch: 030/050 | Batch 200/266 | Loss: 0.2515\n",
            "Epoch: 030/050 | Batch 250/266 | Loss: 0.1408\n",
            "training accuracy: 93.95%\n",
            "valid accuracy: 81.58%\n",
            "Time elapsed: 26.70 min\n",
            "Epoch: 031/050 | Batch 000/266 | Loss: 0.1582\n",
            "Epoch: 031/050 | Batch 050/266 | Loss: 0.2112\n",
            "Epoch: 031/050 | Batch 100/266 | Loss: 0.1110\n",
            "Epoch: 031/050 | Batch 150/266 | Loss: 0.2154\n",
            "Epoch: 031/050 | Batch 200/266 | Loss: 0.2021\n",
            "Epoch: 031/050 | Batch 250/266 | Loss: 0.1668\n",
            "training accuracy: 94.41%\n",
            "valid accuracy: 81.48%\n",
            "Time elapsed: 27.59 min\n",
            "Epoch: 032/050 | Batch 000/266 | Loss: 0.1896\n",
            "Epoch: 032/050 | Batch 050/266 | Loss: 0.1189\n",
            "Epoch: 032/050 | Batch 100/266 | Loss: 0.2502\n",
            "Epoch: 032/050 | Batch 150/266 | Loss: 0.1853\n",
            "Epoch: 032/050 | Batch 200/266 | Loss: 0.2581\n",
            "Epoch: 032/050 | Batch 250/266 | Loss: 0.2903\n",
            "training accuracy: 93.95%\n",
            "valid accuracy: 81.33%\n",
            "Time elapsed: 28.49 min\n",
            "Epoch: 033/050 | Batch 000/266 | Loss: 0.1868\n",
            "Epoch: 033/050 | Batch 050/266 | Loss: 0.1272\n",
            "Epoch: 033/050 | Batch 100/266 | Loss: 0.1343\n",
            "Epoch: 033/050 | Batch 150/266 | Loss: 0.1545\n",
            "Epoch: 033/050 | Batch 200/266 | Loss: 0.2179\n",
            "Epoch: 033/050 | Batch 250/266 | Loss: 0.2966\n",
            "training accuracy: 95.02%\n",
            "valid accuracy: 81.93%\n",
            "Time elapsed: 29.38 min\n",
            "Epoch: 034/050 | Batch 000/266 | Loss: 0.0915\n",
            "Epoch: 034/050 | Batch 050/266 | Loss: 0.1092\n",
            "Epoch: 034/050 | Batch 100/266 | Loss: 0.1986\n",
            "Epoch: 034/050 | Batch 150/266 | Loss: 0.2675\n",
            "Epoch: 034/050 | Batch 200/266 | Loss: 0.1015\n",
            "Epoch: 034/050 | Batch 250/266 | Loss: 0.1512\n",
            "training accuracy: 94.23%\n",
            "valid accuracy: 81.63%\n",
            "Time elapsed: 30.27 min\n",
            "Epoch: 035/050 | Batch 000/266 | Loss: 0.1395\n",
            "Epoch: 035/050 | Batch 050/266 | Loss: 0.1876\n",
            "Epoch: 035/050 | Batch 100/266 | Loss: 0.2126\n",
            "Epoch: 035/050 | Batch 150/266 | Loss: 0.2668\n",
            "Epoch: 035/050 | Batch 200/266 | Loss: 0.2182\n",
            "Epoch: 035/050 | Batch 250/266 | Loss: 0.1173\n",
            "training accuracy: 92.98%\n",
            "valid accuracy: 81.50%\n",
            "Time elapsed: 31.15 min\n",
            "Epoch: 036/050 | Batch 000/266 | Loss: 0.1813\n",
            "Epoch: 036/050 | Batch 050/266 | Loss: 0.2263\n",
            "Epoch: 036/050 | Batch 100/266 | Loss: 0.1642\n",
            "Epoch: 036/050 | Batch 150/266 | Loss: 0.1628\n",
            "Epoch: 036/050 | Batch 200/266 | Loss: 0.2610\n",
            "Epoch: 036/050 | Batch 250/266 | Loss: 0.2294\n",
            "training accuracy: 92.47%\n",
            "valid accuracy: 81.40%\n",
            "Time elapsed: 32.04 min\n",
            "Epoch: 037/050 | Batch 000/266 | Loss: 0.1984\n",
            "Epoch: 037/050 | Batch 050/266 | Loss: 0.2219\n",
            "Epoch: 037/050 | Batch 100/266 | Loss: 0.2397\n",
            "Epoch: 037/050 | Batch 150/266 | Loss: 0.2183\n",
            "Epoch: 037/050 | Batch 200/266 | Loss: 0.2278\n",
            "Epoch: 037/050 | Batch 250/266 | Loss: 0.2238\n",
            "training accuracy: 93.27%\n",
            "valid accuracy: 82.13%\n",
            "Time elapsed: 32.94 min\n",
            "Epoch: 038/050 | Batch 000/266 | Loss: 0.3120\n",
            "Epoch: 038/050 | Batch 050/266 | Loss: 0.1405\n",
            "Epoch: 038/050 | Batch 100/266 | Loss: 0.1545\n",
            "Epoch: 038/050 | Batch 150/266 | Loss: 0.2754\n",
            "Epoch: 038/050 | Batch 200/266 | Loss: 0.2116\n",
            "Epoch: 038/050 | Batch 250/266 | Loss: 0.1703\n",
            "training accuracy: 92.09%\n",
            "valid accuracy: 81.37%\n",
            "Time elapsed: 33.82 min\n",
            "Epoch: 039/050 | Batch 000/266 | Loss: 0.1569\n",
            "Epoch: 039/050 | Batch 050/266 | Loss: 0.2228\n",
            "Epoch: 039/050 | Batch 100/266 | Loss: 0.2185\n",
            "Epoch: 039/050 | Batch 150/266 | Loss: 0.1499\n",
            "Epoch: 039/050 | Batch 200/266 | Loss: 0.2019\n",
            "Epoch: 039/050 | Batch 250/266 | Loss: 0.1447\n",
            "training accuracy: 93.36%\n",
            "valid accuracy: 82.37%\n",
            "Time elapsed: 34.71 min\n",
            "Epoch: 040/050 | Batch 000/266 | Loss: 0.1613\n",
            "Epoch: 040/050 | Batch 050/266 | Loss: 0.1985\n",
            "Epoch: 040/050 | Batch 100/266 | Loss: 0.1634\n",
            "Epoch: 040/050 | Batch 150/266 | Loss: 0.2079\n",
            "Epoch: 040/050 | Batch 200/266 | Loss: 0.1864\n",
            "Epoch: 040/050 | Batch 250/266 | Loss: 0.1249\n",
            "training accuracy: 93.76%\n",
            "valid accuracy: 82.93%\n",
            "Time elapsed: 35.60 min\n",
            "Epoch: 041/050 | Batch 000/266 | Loss: 0.1897\n",
            "Epoch: 041/050 | Batch 050/266 | Loss: 0.1500\n",
            "Epoch: 041/050 | Batch 100/266 | Loss: 0.2308\n",
            "Epoch: 041/050 | Batch 150/266 | Loss: 0.2038\n",
            "Epoch: 041/050 | Batch 200/266 | Loss: 0.2426\n",
            "Epoch: 041/050 | Batch 250/266 | Loss: 0.1828\n",
            "training accuracy: 93.48%\n",
            "valid accuracy: 83.05%\n",
            "Time elapsed: 36.49 min\n",
            "Epoch: 042/050 | Batch 000/266 | Loss: 0.2287\n",
            "Epoch: 042/050 | Batch 050/266 | Loss: 0.2567\n",
            "Epoch: 042/050 | Batch 100/266 | Loss: 0.2443\n",
            "Epoch: 042/050 | Batch 150/266 | Loss: 0.2144\n",
            "Epoch: 042/050 | Batch 200/266 | Loss: 0.3157\n",
            "Epoch: 042/050 | Batch 250/266 | Loss: 0.1667\n",
            "training accuracy: 90.11%\n",
            "valid accuracy: 80.00%\n",
            "Time elapsed: 37.38 min\n",
            "Epoch: 043/050 | Batch 000/266 | Loss: 0.2841\n",
            "Epoch: 043/050 | Batch 050/266 | Loss: 0.1480\n",
            "Epoch: 043/050 | Batch 100/266 | Loss: 0.1887\n",
            "Epoch: 043/050 | Batch 150/266 | Loss: 0.2729\n",
            "Epoch: 043/050 | Batch 200/266 | Loss: 0.2207\n",
            "Epoch: 043/050 | Batch 250/266 | Loss: 0.2333\n",
            "training accuracy: 89.15%\n",
            "valid accuracy: 78.70%\n",
            "Time elapsed: 38.27 min\n",
            "Epoch: 044/050 | Batch 000/266 | Loss: 0.2995\n",
            "Epoch: 044/050 | Batch 050/266 | Loss: 0.1725\n",
            "Epoch: 044/050 | Batch 100/266 | Loss: 0.2222\n",
            "Epoch: 044/050 | Batch 150/266 | Loss: 0.2061\n",
            "Epoch: 044/050 | Batch 200/266 | Loss: 0.1863\n",
            "Epoch: 044/050 | Batch 250/266 | Loss: 0.1989\n",
            "training accuracy: 92.44%\n",
            "valid accuracy: 83.10%\n",
            "Time elapsed: 39.16 min\n",
            "Epoch: 045/050 | Batch 000/266 | Loss: 0.2186\n",
            "Epoch: 045/050 | Batch 050/266 | Loss: 0.1884\n",
            "Epoch: 045/050 | Batch 100/266 | Loss: 0.1523\n",
            "Epoch: 045/050 | Batch 150/266 | Loss: 0.2148\n",
            "Epoch: 045/050 | Batch 200/266 | Loss: 0.2272\n",
            "Epoch: 045/050 | Batch 250/266 | Loss: 0.2513\n",
            "training accuracy: 92.59%\n",
            "valid accuracy: 83.20%\n",
            "Time elapsed: 40.05 min\n",
            "Epoch: 046/050 | Batch 000/266 | Loss: 0.1991\n",
            "Epoch: 046/050 | Batch 050/266 | Loss: 0.3178\n",
            "Epoch: 046/050 | Batch 100/266 | Loss: 0.2245\n",
            "Epoch: 046/050 | Batch 150/266 | Loss: 0.2235\n",
            "Epoch: 046/050 | Batch 200/266 | Loss: 0.2446\n",
            "Epoch: 046/050 | Batch 250/266 | Loss: 0.2192\n",
            "training accuracy: 92.64%\n",
            "valid accuracy: 82.22%\n",
            "Time elapsed: 40.94 min\n",
            "Epoch: 047/050 | Batch 000/266 | Loss: 0.1798\n",
            "Epoch: 047/050 | Batch 050/266 | Loss: 0.2303\n",
            "Epoch: 047/050 | Batch 100/266 | Loss: 0.2892\n",
            "Epoch: 047/050 | Batch 150/266 | Loss: 0.1327\n",
            "Epoch: 047/050 | Batch 200/266 | Loss: 0.1648\n",
            "Epoch: 047/050 | Batch 250/266 | Loss: 0.2482\n",
            "training accuracy: 92.16%\n",
            "valid accuracy: 82.62%\n",
            "Time elapsed: 41.83 min\n",
            "Epoch: 048/050 | Batch 000/266 | Loss: 0.1360\n",
            "Epoch: 048/050 | Batch 050/266 | Loss: 0.1925\n",
            "Epoch: 048/050 | Batch 100/266 | Loss: 0.2783\n",
            "Epoch: 048/050 | Batch 150/266 | Loss: 0.2126\n",
            "Epoch: 048/050 | Batch 200/266 | Loss: 0.1164\n",
            "Epoch: 048/050 | Batch 250/266 | Loss: 0.2749\n",
            "training accuracy: 92.70%\n",
            "valid accuracy: 82.98%\n",
            "Time elapsed: 42.72 min\n",
            "Epoch: 049/050 | Batch 000/266 | Loss: 0.1270\n",
            "Epoch: 049/050 | Batch 050/266 | Loss: 0.2993\n",
            "Epoch: 049/050 | Batch 100/266 | Loss: 0.2531\n",
            "Epoch: 049/050 | Batch 150/266 | Loss: 0.1558\n",
            "Epoch: 049/050 | Batch 200/266 | Loss: 0.3661\n",
            "Epoch: 049/050 | Batch 250/266 | Loss: 0.2605\n",
            "training accuracy: 92.14%\n",
            "valid accuracy: 82.50%\n",
            "Time elapsed: 43.61 min\n",
            "Epoch: 050/050 | Batch 000/266 | Loss: 0.2366\n",
            "Epoch: 050/050 | Batch 050/266 | Loss: 0.3241\n",
            "Epoch: 050/050 | Batch 100/266 | Loss: 0.2918\n",
            "Epoch: 050/050 | Batch 150/266 | Loss: 0.3405\n",
            "Epoch: 050/050 | Batch 200/266 | Loss: 0.2337\n",
            "Epoch: 050/050 | Batch 250/266 | Loss: 0.2575\n",
            "training accuracy: 89.26%\n",
            "valid accuracy: 82.42%\n",
            "Time elapsed: 44.50 min\n",
            "Total Training Time: 44.50 min\n",
            "Test accuracy: 82.03%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    for batch_idx, batch_data in enumerate(train_loader):\n",
        "        \n",
        "        text = batch_data.TEXT_COLUMN_NAME.to(DEVICE)\n",
        "        labels = batch_data.LABEL_COLUMN_NAME.to(DEVICE)\n",
        "\n",
        "        ### FORWARD AND BACK PROP\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        \n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
        "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
        "                   f'Loss: {loss:.4f}')\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print(f'training accuracy: '\n",
        "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
        "              f'\\nvalid accuracy: '\n",
        "              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
        "        \n",
        "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
        "    \n",
        "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EUUKPH1q0c8"
      },
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T16:41:22.981494Z",
          "iopub.status.busy": "2022-01-22T16:41:22.981224Z",
          "iopub.status.idle": "2022-01-22T16:41:23.185798Z",
          "shell.execute_reply": "2022-01-22T16:41:23.185126Z",
          "shell.execute_reply.started": "2022-01-22T16:41:22.981459Z"
        },
        "trusted": true,
        "id": "QSnR72TAq0c8",
        "outputId": "a2a20d3a-9ec5-47b9-c6d2-c02047ec3109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probability positive:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.9985167384147644"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n",
        "    return prediction[0][1].item()\n",
        "\n",
        "print('Probability positive:')\n",
        "predict_sentiment(model, \"This is such an awesome movie, I really love it!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-01-22T16:41:49.753493Z",
          "iopub.status.busy": "2022-01-22T16:41:49.752937Z",
          "iopub.status.idle": "2022-01-22T16:41:49.762087Z",
          "shell.execute_reply": "2022-01-22T16:41:49.761053Z",
          "shell.execute_reply.started": "2022-01-22T16:41:49.753453Z"
        },
        "trusted": true,
        "id": "seInZaDdq0c8",
        "outputId": "ff05422d-f707-4e49-d02c-d110da1da18f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probability positive:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0021373280324041843"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('Probability positive:')\n",
        "predict_sentiment(model, \"I really hate this movie. It is really bad and sucks!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qnVwiRIq0c8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "colab": {
      "name": "coding_assignment.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}